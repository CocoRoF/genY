# ìƒˆë¡œìš´ Node ì„¤ê³„ ê°€ì´ë“œ

## 1. ê°œìš”

ì´ ê°€ì´ë“œëŠ” ì›Œí¬í”Œë¡œìš° ì‹œìŠ¤í…œì— **ìƒˆë¡œìš´ ë…¸ë“œë¥¼ ì¶”ê°€í•˜ëŠ” ë°©ë²•**ì„ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•œë‹¤. ê°„ë‹¨í•œ ë¹„ì¡°ê±´ë¶€ ë…¸ë“œë¶€í„° ë³µì¡í•œ ì¡°ê±´ë¶€ ë¼ìš°íŒ… ë…¸ë“œê¹Œì§€ ëª¨ë“  ìœ í˜•ì„ ë‹¤ë£¬ë‹¤.

## 2. í•µì‹¬ ì›ì¹™

1. **ë‹¨ì¼ ì±…ì„**: í•˜ë‚˜ì˜ ë…¸ë“œëŠ” í•˜ë‚˜ì˜ ëª…í™•í•œ ì‘ì—…ë§Œ ìˆ˜í–‰í•œë‹¤
2. **ìƒíƒœ ê¸°ë°˜**: ë…¸ë“œëŠ” `state`ë¥¼ ì½ê³ , ë³€ê²½í•  í•„ë“œë§Œ ë°˜í™˜í•œë‹¤ (ë¶€ìˆ˜ íš¨ê³¼ ìµœì†Œí™”)
3. **ì„¤ì • ê°€ëŠ¥**: í•˜ë“œì½”ë”© ëŒ€ì‹  `config` íŒŒë¼ë¯¸í„°ë¥¼ í†µí•´ ë™ì‘ì„ ìœ ì—°í•˜ê²Œ ë³€ê²½í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤
4. **ì—ëŸ¬ ì•ˆì „**: ëª¨ë“  ì™¸ë¶€ í˜¸ì¶œ(LLM, ë©”ëª¨ë¦¬ ë“±)ì€ try-catchë¡œ ê°ì‹¸ê³ , ì‹¤íŒ¨ ì‹œ `error` + `is_complete` ë°˜í™˜
5. **ë“±ë¡ í•„ìˆ˜**: `@register_node` ë°ì½”ë ˆì´í„°ë¡œ `NodeRegistry`ì— ë“±ë¡í•´ì•¼ ì‹œìŠ¤í…œì—ì„œ ì¸ì‹ëœë‹¤

## 3. ë¹ ë¥¸ ì‹œì‘: 5ë¶„ ë§Œì— ë…¸ë“œ ë§Œë“¤ê¸°

### 3.1 íŒŒì¼ ìƒì„±

`backend/service/workflow/nodes/` ë””ë ‰í† ë¦¬ì— ìƒˆ Python íŒŒì¼ì„ ìƒì„±í•œë‹¤:

```
backend/service/workflow/nodes/my_nodes.py
```

### 3.2 ê¸°ë³¸ êµ¬ì¡° ì‘ì„±

```python
"""
My Custom Nodes â€” ì‚¬ìš©ì ì •ì˜ ë…¸ë“œ ëª¨ë“ˆ.

ì´ ëª¨ë“ˆì˜ ëª©ì ê³¼ í¬í•¨ëœ ë…¸ë“œë“¤ì— ëŒ€í•œ ì„¤ëª….
"""

from __future__ import annotations

from logging import getLogger
from typing import Any, Dict

from langchain_core.messages import HumanMessage

from service.workflow.nodes.base import (
    BaseNode,
    ExecutionContext,
    NodeParameter,
    OutputPort,
    register_node,
)

logger = getLogger(__name__)


@register_node
class SummaryNode(BaseNode):
    """ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•˜ëŠ” ë…¸ë“œ."""

    # â”€â”€ ë©”íƒ€ë°ì´í„° â”€â”€
    node_type = "summary"
    label = "Summarize"
    description = "ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ì§€ì •ëœ ê¸¸ì´ë¡œ ìš”ì•½í•©ë‹ˆë‹¤"
    category = "model"
    icon = "ğŸ“"
    color = "#10b981"

    # â”€â”€ íŒŒë¼ë¯¸í„° â”€â”€
    parameters = [
        NodeParameter(
            name="prompt_template",
            label="ìš”ì•½ í”„ë¡¬í”„íŠ¸",
            type="prompt_template",
            default="ë‹¤ìŒ ë‚´ìš©ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n{input}",
            required=True,
            description="ìš”ì•½ ìš”ì²­ í”„ë¡¬í”„íŠ¸. {input}ì€ ì‚¬ìš©ì ì…ë ¥ìœ¼ë¡œ ì¹˜í™˜ë©ë‹ˆë‹¤.",
            group="prompt",
        ),
        NodeParameter(
            name="max_length",
            label="ìµœëŒ€ ê¸¸ì´",
            type="number",
            default=500,
            min=50,
            max=5000,
            description="ìš”ì•½ë¬¸ì˜ ìµœëŒ€ ê¸€ì ìˆ˜",
            group="output",
        ),
    ]

    # â”€â”€ ì¶œë ¥ í¬íŠ¸ (ë¹„ì¡°ê±´ë¶€: ê¸°ë³¸ 1ê°œ) â”€â”€
    output_ports = [
        OutputPort(id="default", label="Next"),
    ]

    # â”€â”€ ì‹¤í–‰ â”€â”€
    async def execute(
        self,
        state: Dict[str, Any],
        context: ExecutionContext,
        config: Dict[str, Any],
    ) -> Dict[str, Any]:
        # 1. ì„¤ì •ê°’ ì½ê¸°
        template = config.get("prompt_template", "ìš”ì•½í•´ì£¼ì„¸ìš”: {input}")
        max_length = config.get("max_length", 500)

        # 2. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        input_text = state.get("input", "")
        try:
            prompt = template.format(input=input_text)
        except KeyError:
            prompt = template

        # 3. ëª¨ë¸ í˜¸ì¶œ
        messages = [HumanMessage(content=prompt)]
        try:
            response, fallback = await context.resilient_invoke(
                messages, "summary"
            )
        except Exception as e:
            logger.exception(f"[{context.session_id}] summary error: {e}")
            return {"error": str(e), "is_complete": True}

        # 4. ê²°ê³¼ ì²˜ë¦¬
        summary = response.content[:max_length]

        # 5. ìƒíƒœ ì—…ë°ì´íŠ¸ ë°˜í™˜
        result: Dict[str, Any] = {
            "last_output": summary,
            "messages": [response],
            "current_step": "summary_complete",
        }
        result.update(fallback)
        return result
```

### 3.3 __init__.pyì— ë“±ë¡

`backend/service/workflow/nodes/__init__.py`ì— ìƒˆ ëª¨ë“ˆì˜ importë¥¼ ì¶”ê°€í•œë‹¤:

```python
# nodes/__init__.py
from service.workflow.nodes import model_nodes    # ê¸°ì¡´
from service.workflow.nodes import task_nodes     # ê¸°ì¡´
from service.workflow.nodes import logic_nodes    # ê¸°ì¡´
from service.workflow.nodes import guard_nodes    # ê¸°ì¡´
from service.workflow.nodes import memory_nodes   # ê¸°ì¡´
from service.workflow.nodes import my_nodes       # â† ì¶”ê°€!
```

### 3.4 í™•ì¸

ì„œë²„ ì¬ì‹œì‘ í›„ `GET /api/workflows/nodes` APIë¥¼ í˜¸ì¶œí•˜ë©´ í”„ë¡ íŠ¸ì—”ë“œ ë…¸ë“œ íŒ”ë ˆíŠ¸ì— ìƒˆ ë…¸ë“œê°€ ë‚˜íƒ€ë‚œë‹¤.

## 4. ì¡°ê±´ë¶€ ë…¸ë“œ ë§Œë“¤ê¸°

ì—¬ëŸ¬ ì¶œë ¥ ê²½ë¡œë¥¼ ê°€ì§„ ì¡°ê±´ë¶€(ë¼ìš°íŒ…) ë…¸ë“œë¥¼ ë§Œë“œëŠ” ë°©ë²•ì´ë‹¤.

### 4.1 ì˜ˆì‹œ: ê°ì„± ë¶„ì„ ë¼ìš°í„°

```python
@register_node
class SentimentRouterNode(BaseNode):
    """í…ìŠ¤íŠ¸ ê°ì„±ì„ ë¶„ì„í•˜ì—¬ ê¸ì •/ë¶€ì •/ì¤‘ë¦½ìœ¼ë¡œ ë¼ìš°íŒ…í•˜ëŠ” ë…¸ë“œ."""

    node_type = "sentiment_router"
    label = "Sentiment Router"
    description = "í…ìŠ¤íŠ¸ ê°ì„±ì„ ë¶„ì„í•˜ì—¬ ê²½ë¡œë¥¼ ë¶„ê¸°í•©ë‹ˆë‹¤"
    category = "logic"
    icon = "ğŸ”€"
    color = "#6366f1"

    parameters = [
        NodeParameter(
            name="input_field",
            label="ë¶„ì„ ëŒ€ìƒ í•„ë“œ",
            type="string",
            default="last_output",
            description="ê°ì„± ë¶„ì„í•  ìƒíƒœ í•„ë“œ ì´ë¦„",
            group="routing",
        ),
    ]

    # â”€â”€ ë³µìˆ˜ ì¶œë ¥ í¬íŠ¸ ì •ì˜ â”€â”€
    output_ports = [
        OutputPort(id="positive", label="Positive", description="ê¸ì •ì  ê°ì„±"),
        OutputPort(id="negative", label="Negative", description="ë¶€ì •ì  ê°ì„±"),
        OutputPort(id="neutral",  label="Neutral",  description="ì¤‘ë¦½ì  ê°ì„±"),
    ]

    async def execute(
        self,
        state: Dict[str, Any],
        context: ExecutionContext,
        config: Dict[str, Any],
    ) -> Dict[str, Any]:
        input_field = config.get("input_field", "last_output")
        text = state.get(input_field, "")

        prompt = f"ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì„±ì„ ë¶„ì„í•˜ì„¸ìš”. ë°˜ë“œì‹œ 'positive', 'negative', 'neutral' ì¤‘ í•˜ë‚˜ë§Œ ë‹µí•˜ì„¸ìš”.\n\n{text}"
        messages = [HumanMessage(content=prompt)]

        try:
            response, fallback = await context.resilient_invoke(
                messages, "sentiment_router"
            )
            sentiment = response.content.strip().lower()

            if "positive" in sentiment:
                result_sentiment = "positive"
            elif "negative" in sentiment:
                result_sentiment = "negative"
            else:
                result_sentiment = "neutral"

            result: Dict[str, Any] = {
                "metadata": {**state.get("metadata", {}), "sentiment": result_sentiment},
                "last_output": response.content,
                "current_step": "sentiment_analyzed",
            }
            result.update(fallback)
            return result

        except Exception as e:
            return {
                "metadata": {**state.get("metadata", {}), "sentiment": "neutral"},
                "error": str(e),
                "current_step": "sentiment_error",
            }

    # â”€â”€ ë¼ìš°íŒ… í•¨ìˆ˜ (í•„ìˆ˜!) â”€â”€
    def get_routing_function(self, config):
        """ìƒíƒœì˜ metadata.sentiment ê°’ì— ë”°ë¼ ë¼ìš°íŒ…"""
        def _route(state: Dict[str, Any]) -> str:
            metadata = state.get("metadata", {})
            sentiment = metadata.get("sentiment", "neutral")
            if sentiment in ("positive", "negative", "neutral"):
                return sentiment
            return "neutral"
        return _route
```

### 4.2 ì¡°ê±´ë¶€ ë…¸ë“œì˜ í•µì‹¬ ê·œì¹™

1. **`output_ports`ê°€ 2ê°œ ì´ìƒ** â†’ `is_conditional == True`
2. **`get_routing_function(config)`ë¥¼ ë°˜ë“œì‹œ êµ¬í˜„** â†’ ìƒíƒœë¥¼ ë³´ê³  í¬íŠ¸ IDë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
3. **ë°˜í™˜í•˜ëŠ” í¬íŠ¸ IDê°€ `output_ports`ì˜ `id`ì™€ ì¼ì¹˜**í•´ì•¼ í•¨
4. **`execute()`ì—ì„œ ë¼ìš°íŒ…ì— í•„ìš”í•œ ìƒíƒœ í•„ë“œë¥¼ ë°˜ë“œì‹œ ì„¤ì •**í•´ì•¼ í•¨

## 5. ìˆœìˆ˜ ë¡œì§ ë…¸ë“œ(LLM í˜¸ì¶œ ì—†ìŒ)

ëª¨ë¸ì„ í˜¸ì¶œí•˜ì§€ ì•Šê³  ìƒíƒœë§Œ ê²€ì‚¬/ë³€ê²½í•˜ëŠ” ë…¸ë“œ:

```python
@register_node
class ThresholdGateNode(BaseNode):
    """iteration íšŸìˆ˜ê°€ ì„ê³„ê°’ì— ë„ë‹¬í–ˆëŠ”ì§€ ê²€ì‚¬í•˜ëŠ” ê²Œì´íŠ¸ ë…¸ë“œ."""

    node_type = "threshold_gate"
    label = "Threshold Gate"
    description = "ë°˜ë³µ íšŸìˆ˜ê°€ ì„ê³„ê°’ì— ë„ë‹¬í•˜ë©´ ì¤‘ë‹¨í•©ë‹ˆë‹¤"
    category = "logic"
    icon = "ğŸš§"
    color = "#f59e0b"

    parameters = [
        NodeParameter(
            name="threshold",
            label="Threshold",
            type="number",
            default=10,
            min=1,
            max=100,
            description="ì´ íšŸìˆ˜ì— ë„ë‹¬í•˜ë©´ stop í¬íŠ¸ë¡œ ë¼ìš°íŒ…",
            group="routing",
        ),
    ]

    output_ports = [
        OutputPort(id="continue", label="Continue", description="ì„ê³„ê°’ ë¯¸ë‹¬"),
        OutputPort(id="stop",     label="Stop",     description="ì„ê³„ê°’ ë„ë‹¬"),
    ]

    async def execute(self, state, context, config):
        # LLM í˜¸ì¶œ ì—†ì´ ìƒíƒœë§Œ ê²€ì‚¬
        return {"current_step": "threshold_checked"}

    def get_routing_function(self, config):
        threshold = config.get("threshold", 10)

        def _route(state):
            iteration = state.get("iteration", 0)
            if iteration >= threshold:
                return "stop"
            return "continue"
        return _route
```

## 6. ìƒíƒœ ì»¤ìŠ¤í…€ í™•ì¥

### 6.1 ê¸°ì¡´ ìƒíƒœ í•„ë“œ í™œìš©

ê°€ëŠ¥í•˜ë©´ `AutonomousState`ì— ì´ë¯¸ ì •ì˜ëœ í•„ë“œë¥¼ í™œìš©í•œë‹¤:

| í•„ë“œ | ìš©ë„ | ì‚¬ìš© ì˜ˆì‹œ |
|---|---|---|
| `last_output` | ìµœê·¼ ëª¨ë¸ ì‘ë‹µ | ë²”ìš©ì ìœ¼ë¡œ ì‚¬ìš© |
| `metadata` | ì»¤ìŠ¤í…€ ë°ì´í„° ì €ì¥ | `metadata["sentiment"]` |
| `answer` | ì¤‘ê°„ ë‹µë³€ | Medium ê²½ë¡œìš© |
| `final_answer` | ìµœì¢… ë‹µë³€ | ê²°ê³¼ ì „ë‹¬ìš© |
| `messages` | ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ | ëŒ€í™” ë§¥ë½ ìœ ì§€ |

### 6.2 metadata ë”•ì…”ë„ˆë¦¬ í™œìš©

ìƒˆë¡œìš´ ìƒíƒœ í•„ë“œê°€ í•„ìš”í•˜ì§€ë§Œ `AutonomousState`ë¥¼ ë³€ê²½í•˜ê³  ì‹¶ì§€ ì•Šì„ ë•Œ:

```python
# ì“°ê¸°
return {
    "metadata": {
        **state.get("metadata", {}),
        "my_custom_field": "value",
        "analysis_result": {"score": 0.95},
    }
}

# ì½ê¸° (ë‹¤ìŒ ë…¸ë“œì—ì„œ)
async def execute(self, state, context, config):
    metadata = state.get("metadata", {})
    custom_value = metadata.get("my_custom_field")
```

### 6.3 AutonomousState í™•ì¥ (ê³ ê¸‰)

ì •ë§ í•„ìš”í•œ ê²½ìš° `state.py`ì— ìƒˆ í•„ë“œë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆë‹¤:

```python
# state.pyì— ì¶”ê°€
class AutonomousState(TypedDict, total=False):
    # ... ê¸°ì¡´ í•„ë“œ ...
    my_new_field: Optional[str]  # ìƒˆ í•„ë“œ ì¶”ê°€
```

> **ì£¼ì˜**: ìƒíƒœ í™•ì¥ì€ ì „ì²´ ì‹œìŠ¤í…œì— ì˜í–¥ì„ ë¯¸ì¹˜ë¯€ë¡œ ì‹ ì¤‘í•˜ê²Œ ê²°ì •í•´ì•¼ í•œë‹¤. ê°€ëŠ¥í•˜ë©´ `metadata` ë”•ì…”ë„ˆë¦¬ë¥¼ ë¨¼ì € ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•œë‹¤.

## 7. ë…¸ë“œ íŒŒë¼ë¯¸í„° ì„¤ê³„ ì§€ì¹¨

### 7.1 ì¢‹ì€ íŒŒë¼ë¯¸í„° ì„¤ê³„

```python
parameters = [
    # âœ… ëª©ì ì´ ëª…í™•í•œ íŒŒë¼ë¯¸í„°
    NodeParameter(
        name="prompt_template",
        label="í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿",
        type="prompt_template",
        default="ê¸°ë³¸ í”„ë¡¬í”„íŠ¸: {input}",
        required=True,
        description="ëª¨ë¸ì—ê²Œ ë³´ë‚¼ í”„ë¡¬í”„íŠ¸. {input}ìœ¼ë¡œ ì‚¬ìš©ì ì…ë ¥ì„ ì°¸ì¡°í•©ë‹ˆë‹¤.",
        group="prompt",
    ),

    # âœ… ë²”ìœ„ê°€ ì œí•œëœ ìˆ«ì íŒŒë¼ë¯¸í„°
    NodeParameter(
        name="max_tokens",
        label="ìµœëŒ€ í† í°",
        type="number",
        default=1000,
        min=100,
        max=10000,
        description="ì‘ë‹µì˜ ìµœëŒ€ í† í° ìˆ˜",
        group="advanced",
    ),

    # âœ… ì„ íƒì§€ê°€ ëª…í™•í•œ select íŒŒë¼ë¯¸í„°
    NodeParameter(
        name="language",
        label="ì¶œë ¥ ì–¸ì–´",
        type="select",
        default="ko",
        options=[
            {"label": "í•œêµ­ì–´", "value": "ko"},
            {"label": "English", "value": "en"},
            {"label": "æ—¥æœ¬èª", "value": "ja"},
        ],
        group="output",
    ),
]
```

### 7.2 í”¼í•´ì•¼ í•  íŒ¨í„´

```python
parameters = [
    # âŒ ë„ˆë¬´ ë²”ìš©ì ì¸ íŒŒë¼ë¯¸í„°
    NodeParameter(name="data", label="Data", type="json", default="{}"),

    # âŒ ì„¤ëª…ì´ ì—†ëŠ” íŒŒë¼ë¯¸í„°
    NodeParameter(name="x", label="X", type="number"),

    # âŒ ë²”ìœ„ê°€ ì—†ëŠ” ìˆ«ì íŒŒë¼ë¯¸í„°
    NodeParameter(name="count", label="Count", type="number", default=0),
]
```

### 7.3 íŒŒë¼ë¯¸í„° ê·¸ë£¹

ê´€ë ¨ëœ íŒŒë¼ë¯¸í„°ë¥¼ `group`ìœ¼ë¡œ ë¬¶ì–´ UIì—ì„œ íƒ­/ì„¹ì…˜ìœ¼ë¡œ í‘œì‹œí•œë‹¤:

| ê·¸ë£¹ | ìš©ë„ |
|---|---|
| `prompt` | í”„ë¡¬í”„íŠ¸ ê´€ë ¨ ì„¤ì • |
| `routing` | ë¼ìš°íŒ…/ë¶„ê¸° ê´€ë ¨ ì„¤ì • |
| `output` | ì¶œë ¥ í˜•ì‹/ëŒ€ìƒ ê´€ë ¨ |
| `advanced` | ê³ ê¸‰ ì„¤ì • |
| `general` | (ê¸°ë³¸) ì¼ë°˜ ì„¤ì • |

## 8. í…ŒìŠ¤íŠ¸

### 8.1 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

```python
import pytest
from unittest.mock import AsyncMock, MagicMock

from service.workflow.nodes.my_nodes import SummaryNode
from service.workflow.nodes.base import ExecutionContext


@pytest.fixture
def mock_context():
    ctx = ExecutionContext(
        model=AsyncMock(),
        session_id="test-session",
    )
    # resilient_invoke ëª¨í‚¹
    mock_response = MagicMock()
    mock_response.content = "ì´ê²ƒì€ ìš”ì•½ì…ë‹ˆë‹¤."
    ctx.resilient_invoke = AsyncMock(return_value=(mock_response, {}))
    return ctx


@pytest.mark.asyncio
async def test_summary_node(mock_context):
    node = SummaryNode()

    state = {
        "input": "ë§¤ìš° ê¸´ í…ìŠ¤íŠ¸...",
        "messages": [],
        "iteration": 0,
    }
    config = {
        "prompt_template": "ìš”ì•½í•´ì£¼ì„¸ìš”: {input}",
        "max_length": 100,
    }

    result = await node.execute(state, mock_context, config)

    assert "last_output" in result
    assert result["current_step"] == "summary_complete"
    assert len(result["last_output"]) <= 100


@pytest.mark.asyncio
async def test_summary_node_error(mock_context):
    mock_context.resilient_invoke = AsyncMock(side_effect=Exception("API Error"))

    node = SummaryNode()
    state = {"input": "test"}
    config = {}

    result = await node.execute(state, mock_context, config)

    assert result.get("error") == "API Error"
    assert result.get("is_complete") is True
```

### 8.2 í†µí•© í…ŒìŠ¤íŠ¸ (ì›Œí¬í”Œë¡œìš° í¸ì§‘ê¸°ì—ì„œ)

1. í”„ë¡ íŠ¸ì—”ë“œ ì›Œí¬í”Œë¡œìš° í¸ì§‘ê¸°ì—ì„œ ìƒˆ ë…¸ë“œë¥¼ ë°°ì¹˜
2. íŒŒë¼ë¯¸í„° ì„¤ì •
3. ì—£ì§€ ì—°ê²°
4. Validate ì‹¤í–‰ â†’ ì—ëŸ¬ ì—†ëŠ”ì§€ í™•ì¸
5. Execute ì‹¤í–‰ â†’ ê¸°ëŒ€í•œ ê²°ê³¼ê°€ ë‚˜ì˜¤ëŠ”ì§€ í™•ì¸

## 9. ì²´í¬ë¦¬ìŠ¤íŠ¸

ìƒˆ ë…¸ë“œë¥¼ ë§Œë“¤ê¸° ì „ì— í™•ì¸í•  ì‚¬í•­:

- [ ] `node_type`ì´ ê¸°ì¡´ ë…¸ë“œì™€ ì¤‘ë³µë˜ì§€ ì•ŠëŠ”ê°€?
- [ ] `@register_node` ë°ì½”ë ˆì´í„°ë¥¼ ë¶™ì˜€ëŠ”ê°€?
- [ ] `nodes/__init__.py`ì— ëª¨ë“ˆ importë¥¼ ì¶”ê°€í–ˆëŠ”ê°€?
- [ ] `execute()` ë©”ì„œë“œë¥¼ êµ¬í˜„í–ˆëŠ”ê°€?
- [ ] ì¡°ê±´ë¶€ ë…¸ë“œì¸ ê²½ìš° `get_routing_function()`ì„ êµ¬í˜„í–ˆëŠ”ê°€?
- [ ] ì¡°ê±´ë¶€ ë…¸ë“œì¸ ê²½ìš° `output_ports`ë¥¼ 2ê°œ ì´ìƒ ì •ì˜í–ˆëŠ”ê°€?
- [ ] ëª¨ë“  LLM í˜¸ì¶œì— try-catchë¥¼ ì ìš©í–ˆëŠ”ê°€?
- [ ] ì—ëŸ¬ ì‹œ `{"error": str(e), "is_complete": True}`ë¥¼ ë°˜í™˜í•˜ëŠ”ê°€?
- [ ] `current_step` í•„ë“œë¥¼ ì—…ë°ì´íŠ¸í•˜ì—¬ ì‹¤í–‰ ì¶”ì ì´ ê°€ëŠ¥í•œê°€?
- [ ] íŒŒë¼ë¯¸í„°ì— ì ì ˆí•œ descriptionê³¼ groupì´ ì„¤ì •ë˜ì—ˆëŠ”ê°€?

## 10. ì „ì²´ ì˜ˆì‹œ: ì›¹ ê²€ìƒ‰ ë…¸ë“œ

ì¢…í•©ì ì¸ ì˜ˆì‹œë¡œ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLMì— ì „ë‹¬í•˜ëŠ” ë…¸ë“œë¥¼ ë§Œë“¤ì–´ ë³¸ë‹¤:

```python
"""
Web Search Node â€” ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ëª¨ë¸ì— ì „ë‹¬í•˜ëŠ” ë…¸ë“œ.
"""

from __future__ import annotations

from logging import getLogger
from typing import Any, Callable, Dict, List, Optional

from langchain_core.messages import HumanMessage

from service.workflow.nodes.base import (
    BaseNode,
    ExecutionContext,
    NodeParameter,
    OutputPort,
    register_node,
)

logger = getLogger(__name__)


@register_node
class WebSearchNode(BaseNode):
    """ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ëª¨ë¸ì— ì „ë‹¬í•˜ëŠ” ë…¸ë“œ.

    ì™¸ë¶€ ê²€ìƒ‰ APIë¥¼ í˜¸ì¶œí•œ ë’¤, ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì£¼ì…í•˜ì—¬
    ëª¨ë¸ì´ ìµœì‹  ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µí•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.
    """

    node_type = "web_search"
    label = "Web Search"
    description = "ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë¸ì´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤"
    category = "model"
    icon = "ğŸ”"
    color = "#0ea5e9"

    parameters = [
        NodeParameter(
            name="search_query_template",
            label="ê²€ìƒ‰ ì¿¼ë¦¬ í…œí”Œë¦¿",
            type="prompt_template",
            default="{input}",
            required=True,
            description="ê²€ìƒ‰ ì—”ì§„ì— ë³´ë‚¼ ì¿¼ë¦¬. {input}ìœ¼ë¡œ ì‚¬ìš©ì ì…ë ¥ ì°¸ì¡°.",
            group="search",
        ),
        NodeParameter(
            name="max_results",
            label="ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜",
            type="number",
            default=5,
            min=1,
            max=20,
            description="ê°€ì ¸ì˜¬ ê²€ìƒ‰ ê²°ê³¼ì˜ ìµœëŒ€ ê°œìˆ˜",
            group="search",
        ),
        NodeParameter(
            name="answer_template",
            label="ë‹µë³€ í”„ë¡¬í”„íŠ¸",
            type="prompt_template",
            default="ë‹¤ìŒ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.\n\nê²€ìƒ‰ê²°ê³¼:\n{search_results}\n\nì§ˆë¬¸: {input}",
            required=True,
            description="ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬í•¨í•œ ë‹µë³€ ìƒì„± í”„ë¡¬í”„íŠ¸",
            group="prompt",
        ),
        NodeParameter(
            name="has_results_routing",
            label="ê²€ìƒ‰ ê²°ê³¼ ìœ ë¬´ ë¼ìš°íŒ…",
            type="boolean",
            default=False,
            description="Trueë¡œ ì„¤ì •í•˜ë©´ ê²€ìƒ‰ ê²°ê³¼ ìœ ë¬´ì— ë”°ë¼ ë‹¤ë¥¸ ê²½ë¡œë¡œ ë¶„ê¸°í•©ë‹ˆë‹¤",
            group="routing",
        ),
    ]

    output_ports = [
        OutputPort(id="default",    label="Next",       description="ê¸°ë³¸ ì¶œë ¥"),
        OutputPort(id="no_results", label="No Results", description="ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"),
    ]

    @property
    def is_conditional(self) -> bool:
        # configì— ë”°ë¼ ì¡°ê±´ë¶€ ì—¬ë¶€ê°€ ë‹¬ë¼ì§€ì§€ë§Œ,
        # ì¶œë ¥ í¬íŠ¸ê°€ 2ê°œì´ë¯€ë¡œ í•­ìƒ True
        return True

    async def execute(
        self,
        state: Dict[str, Any],
        context: ExecutionContext,
        config: Dict[str, Any],
    ) -> Dict[str, Any]:
        query_template = config.get("search_query_template", "{input}")
        max_results = config.get("max_results", 5)
        answer_template = config.get("answer_template", "{input}")
        input_text = state.get("input", "")

        # 1. ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
        try:
            query = query_template.format(input=input_text)
        except KeyError:
            query = input_text

        # 2. ì›¹ ê²€ìƒ‰ ìˆ˜í–‰ (ì‹¤ì œ êµ¬í˜„ì€ ì™¸ë¶€ ì„œë¹„ìŠ¤ ì—°ë™ í•„ìš”)
        try:
            search_results = await self._do_search(query, max_results)
        except Exception as e:
            logger.warning(f"[{context.session_id}] web_search failed: {e}")
            search_results = []

        if not search_results:
            return {
                "metadata": {**state.get("metadata", {}), "search_found": False},
                "last_output": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.",
                "current_step": "web_search_no_results",
            }

        # 3. ê²€ìƒ‰ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…
        results_text = "\n\n".join(
            f"[{i+1}] {r['title']}\n{r['snippet']}"
            for i, r in enumerate(search_results)
        )

        # 4. ë‹µë³€ ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        try:
            prompt = answer_template.format(
                input=input_text,
                search_results=results_text,
            )
        except KeyError:
            prompt = f"{results_text}\n\n{input_text}"

        # 5. ëª¨ë¸ í˜¸ì¶œ
        messages = [HumanMessage(content=prompt)]
        try:
            response, fallback = await context.resilient_invoke(
                messages, "web_search"
            )
        except Exception as e:
            return {"error": str(e), "is_complete": True}

        # 6. ê²°ê³¼ ë°˜í™˜
        result: Dict[str, Any] = {
            "last_output": response.content,
            "messages": [response],
            "metadata": {
                **state.get("metadata", {}),
                "search_found": True,
                "search_result_count": len(search_results),
            },
            "current_step": "web_search_complete",
        }
        result.update(fallback)
        return result

    def get_routing_function(self, config):
        has_routing = config.get("has_results_routing", False)

        def _route(state: Dict[str, Any]) -> str:
            if not has_routing:
                return "default"
            metadata = state.get("metadata", {})
            if not metadata.get("search_found", True):
                return "no_results"
            return "default"
        return _route

    async def _do_search(self, query: str, max_results: int) -> List[Dict]:
        """ì›¹ ê²€ìƒ‰ ìˆ˜í–‰ (í”Œë ˆì´ìŠ¤í™€ë” â€” ì‹¤ì œ êµ¬í˜„ ì‹œ API ì—°ë™ í•„ìš”)"""
        # TODO: ì‹¤ì œ ê²€ìƒ‰ API ì—°ë™
        # ì˜ˆ: Google Custom Search, Bing Search, Tavily ë“±
        return []
```

## 11. ì¹´í…Œê³ ë¦¬ë³„ ë…¸ë“œ ì„¤ê³„ íŒ

### model ì¹´í…Œê³ ë¦¬
- ë°˜ë“œì‹œ `context.resilient_invoke()` ì‚¬ìš© (ìˆ˜ë™ model í˜¸ì¶œ ê¸ˆì§€)
- `prompt_template` íŒŒë¼ë¯¸í„°ë¥¼ ì œê³µí•˜ì—¬ ì‚¬ìš©ìê°€ í”„ë¡¬í”„íŠ¸ë¥¼ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•  ìˆ˜ ìˆë„ë¡
- ì‘ë‹µì„ íŒŒì‹±í•  ë•Œ ë‹¤ì–‘í•œ í˜•ì‹ì— ëŒ€ë¹„ (JSON, í…ìŠ¤íŠ¸, ë§ˆí¬ë‹¤ìš´ ë“±)

### logic ì¹´í…Œê³ ë¦¬
- LLM í˜¸ì¶œ ì—†ì´ ìˆœìˆ˜ ìƒíƒœ ê²€ì‚¬/ë³€í™˜ë§Œ ìˆ˜í–‰
- `execute()`ëŠ” ê°„ê²°í•˜ê²Œ, í•µì‹¬ ë¡œì§ì€ `get_routing_function()`ì—
- ë¬´í•œ ë£¨í”„ ë°©ì§€ë¥¼ ìœ„í•´ iteration/budget ì²´í¬ ê³ ë ¤

### memory ì¹´í…Œê³ ë¦¬
- `context.memory_manager`ê°€ Noneì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ í•­ìƒ ì²´í¬
- `memory_refs` ë¦¬ìŠ¤íŠ¸ë¡œ ì£¼ì… ê¸°ë¡ ë‚¨ê¸°ê¸°
- ì¤‘ë³µ ì£¼ì… ë°©ì§€ ë¡œì§ ê³ ë ¤

### resilience ì¹´í…Œê³ ë¦¬
- ë‹¤ë¥¸ ë…¸ë“œì˜ ì‹¤í–‰ ì „/í›„ì— ë°°ì¹˜ë˜ëŠ” ê°€ë“œ ë…¸ë“œ
- `context.context_guard`ê°€ Noneì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì²´í¬
- BLOCK ìƒíƒœ ì‹œ `is_complete = True` ì„¤ì •

### task ì¹´í…Œê³ ë¦¬
- `todos` ë¦¬ìŠ¤íŠ¸ì™€ `current_todo_index` í™œìš©
- `_merge_todos` ë¦¬ë“€ì„œë¥¼ í™œìš©í•œ ì ì§„ì  ì—…ë°ì´íŠ¸
- ê°œë³„ TODO í•­ëª©ì˜ ìƒíƒœ ì¶”ì  (`pending` â†’ `in_progress` â†’ `completed`/`failed`)
